{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "9d8fbc93-3148-41d1-ab8e-1ec42681ae7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d78a310-2a2d-4ab2-b180-98ebb67998e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from environment import RNAInvEnvironment, make_vec_env"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "2a0a0611-cc1f-4998-ad92-194815047030",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_steps = 512"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "9aeed67c-4ab9-4129-91b1-02bbb7d3e212",
   "metadata": {},
   "outputs": [],
   "source": [
    "# objective_structure = '(((((((....(((...........)))((((((((..(((((((((((((((((((...(((((......))))).)))))).)))))))))))))..))))))))..)))))))'\n",
    "objective_structure = '(((((((((((((((.(((((.((.....)).((.....)).((.....)).((.....)).((.....)).))))).(((.....))).(((((.((.....)).((.....)).((.....)).((.....)).((.....)).))))).(((.....))).(((((.((.....)).((.....)).((.....)).((.....)).((.....)).))))).(((.....))).(((((.((.....)).((.....)).((.....)).((.....)).((.....)).))))).(((.....))).(((((.((.....)).((.....)).((.....)).((.....)).((.....)).))))).)))))))))))))))'\n",
    "n_envs=12\n",
    "env = make_vec_env(RNAInvEnvironment, n_envs=n_envs, env_kwargs={'objective_structure': objective_structure, 'max_steps': max_steps})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "fc0f704e-0fe1-4841-b2af-d0173b63ea79",
   "metadata": {},
   "outputs": [],
   "source": [
    "from stable_baselines3 import PPO\n",
    "from stable_baselines3.common.callbacks import EvalCallback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "5da7e0b4-c8d5-42cb-b4e7-ca80404eaff8",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = PPO(\n",
    "    \"MultiInputPolicy\",\n",
    "    env,\n",
    "    verbose=0,\n",
    "    tensorboard_log='tensorboard_logs',\n",
    "    n_steps=max_steps,\n",
    "    gamma=0.99\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "cc77162e-c3e1-43bc-a316-4c3c7f46e1d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.policy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "94faa1ad-4164-4488-b59e-0eeecf7292c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_env = make_vec_env(\n",
    "    RNAInvEnvironment, n_envs=1,\n",
    "    env_kwargs={'objective_structure': objective_structure, 'max_steps': 2*max_steps}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "fd71229b-f87c-4228-9d9c-cdfdf39c5045",
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_callback = EvalCallback(\n",
    "    eval_env = eval_env,\n",
    "    eval_freq=5*max_steps,\n",
    "    n_eval_episodes=5,\n",
    "    deterministic=True,\n",
    "    verbose=1,\n",
    "    best_model_save_path='models/',\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "8b2c0680-0e8e-42c8-af6d-442e5a933215",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('test_dia_y_medio')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "718fc440-11fd-44b4-a991-aaadb84d1af4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=12288, episode_reward=93.98 +/- 10.01\n",
      "Episode length: 1024.00 +/- 0.00\n",
      "New best mean reward!\n",
      "Eval num_timesteps=43008, episode_reward=94.34 +/- 24.74\n",
      "Episode length: 1024.00 +/- 0.00\n",
      "New best mean reward!\n",
      "Eval num_timesteps=73728, episode_reward=97.18 +/- 6.36\n",
      "Episode length: 1024.00 +/- 0.00\n",
      "New best mean reward!\n",
      "Eval num_timesteps=104448, episode_reward=90.20 +/- 12.62\n",
      "Episode length: 1024.00 +/- 0.00\n",
      "Eval num_timesteps=135168, episode_reward=93.98 +/- 11.18\n",
      "Episode length: 1024.00 +/- 0.00\n",
      "Eval num_timesteps=165888, episode_reward=108.22 +/- 16.73\n",
      "Episode length: 1024.00 +/- 0.00\n",
      "New best mean reward!\n",
      "Eval num_timesteps=196608, episode_reward=101.02 +/- 20.37\n",
      "Episode length: 1024.00 +/- 0.00\n",
      "Eval num_timesteps=227328, episode_reward=97.44 +/- 14.16\n",
      "Episode length: 1024.00 +/- 0.00\n",
      "Eval num_timesteps=258048, episode_reward=114.24 +/- 22.59\n",
      "Episode length: 1024.00 +/- 0.00\n",
      "New best mean reward!\n",
      "Eval num_timesteps=288768, episode_reward=105.88 +/- 11.66\n",
      "Episode length: 1024.00 +/- 0.00\n",
      "Eval num_timesteps=319488, episode_reward=100.18 +/- 12.75\n",
      "Episode length: 1024.00 +/- 0.00\n",
      "Eval num_timesteps=350208, episode_reward=102.24 +/- 13.45\n",
      "Episode length: 1024.00 +/- 0.00\n",
      "Eval num_timesteps=380928, episode_reward=104.06 +/- 10.30\n",
      "Episode length: 1024.00 +/- 0.00\n",
      "Eval num_timesteps=411648, episode_reward=105.40 +/- 15.77\n",
      "Episode length: 1024.00 +/- 0.00\n",
      "Eval num_timesteps=442368, episode_reward=117.18 +/- 7.91\n",
      "Episode length: 1024.00 +/- 0.00\n",
      "New best mean reward!\n",
      "Eval num_timesteps=473088, episode_reward=117.26 +/- 14.65\n",
      "Episode length: 1024.00 +/- 0.00\n",
      "New best mean reward!\n",
      "Eval num_timesteps=503808, episode_reward=117.72 +/- 2.69\n",
      "Episode length: 1024.00 +/- 0.00\n",
      "New best mean reward!\n",
      "Eval num_timesteps=534528, episode_reward=113.18 +/- 9.29\n",
      "Episode length: 1024.00 +/- 0.00\n",
      "Eval num_timesteps=565248, episode_reward=136.40 +/- 13.49\n",
      "Episode length: 1024.00 +/- 0.00\n",
      "New best mean reward!\n",
      "Eval num_timesteps=595968, episode_reward=134.80 +/- 11.68\n",
      "Episode length: 1024.00 +/- 0.00\n",
      "Eval num_timesteps=626688, episode_reward=120.22 +/- 8.48\n",
      "Episode length: 1024.00 +/- 0.00\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<timed eval>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n",
      "\u001b[0;32m/opt/tljh/user/lib/python3.7/site-packages/stable_baselines3/ppo/ppo.py\u001b[0m in \u001b[0;36mlearn\u001b[0;34m(self, total_timesteps, callback, log_interval, eval_env, eval_freq, n_eval_episodes, tb_log_name, eval_log_path, reset_num_timesteps)\u001b[0m\n\u001b[1;32m    306\u001b[0m             \u001b[0mtb_log_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtb_log_name\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    307\u001b[0m             \u001b[0meval_log_path\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0meval_log_path\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 308\u001b[0;31m             \u001b[0mreset_num_timesteps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreset_num_timesteps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    309\u001b[0m         )\n",
      "\u001b[0;32m/opt/tljh/user/lib/python3.7/site-packages/stable_baselines3/common/on_policy_algorithm.py\u001b[0m in \u001b[0;36mlearn\u001b[0;34m(self, total_timesteps, callback, log_interval, eval_env, eval_freq, n_eval_episodes, tb_log_name, eval_log_path, reset_num_timesteps)\u001b[0m\n\u001b[1;32m    232\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_timesteps\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mtotal_timesteps\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    233\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 234\u001b[0;31m             \u001b[0mcontinue_training\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollect_rollouts\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrollout_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_rollout_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_steps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    235\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    236\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mcontinue_training\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/tljh/user/lib/python3.7/site-packages/stable_baselines3/common/on_policy_algorithm.py\u001b[0m in \u001b[0;36mcollect_rollouts\u001b[0;34m(self, env, callback, rollout_buffer, n_rollout_steps)\u001b[0m\n\u001b[1;32m    173\u001b[0m                 \u001b[0mclipped_actions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mactions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maction_space\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlow\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maction_space\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhigh\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    174\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 175\u001b[0;31m             \u001b[0mnew_obs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrewards\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdones\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minfos\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclipped_actions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    176\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    177\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_timesteps\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_envs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/tljh/user/lib/python3.7/site-packages/stable_baselines3/common/vec_env/base_vec_env.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, actions)\u001b[0m\n\u001b[1;32m    160\u001b[0m         \"\"\"\n\u001b[1;32m    161\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mactions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 162\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    163\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    164\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_images\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mSequence\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/tljh/user/lib/python3.7/site-packages/stable_baselines3/common/vec_env/dummy_vec_env.py\u001b[0m in \u001b[0;36mstep_wait\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     42\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0menv_idx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_envs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m             obs, self.buf_rews[env_idx], self.buf_dones[env_idx], self.buf_infos[env_idx] = self.envs[env_idx].step(\n\u001b[0;32m---> 44\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mactions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0menv_idx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m             )\n\u001b[1;32m     46\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuf_dones\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0menv_idx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/tljh/user/lib/python3.7/site-packages/stable_baselines3/common/monitor.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, action)\u001b[0m\n\u001b[1;32m     88\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mneeds_reset\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Tried to step environment that needs reset\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 90\u001b[0;31m         \u001b[0mobservation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreward\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minfo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     91\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrewards\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreward\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mdone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/rna_inv_folding/environment.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, action)\u001b[0m\n\u001b[1;32m     95\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msteps\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msteps\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 97\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maction_to_state\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     98\u001b[0m         \u001b[0mcurrent_structure\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0menergy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mRNA\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfold\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m         \u001b[0mdone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mcurrent_structure\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobjective_structure\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msteps\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_steps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# CPU times: user 1d 16h 56min 26s, sys: 19.5 s, total: 1d 16h 56min 46s\n",
    "# Wall time: 1d 16h 56min 23s\n",
    "\n",
    "model.learn(\n",
    "    total_timesteps=1_000_000,\n",
    "    callback=[eval_callback]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78bb47a0-b750-43d7-8bab-8d2e3acd322f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eba56777-8820-4fd2-9361-4c0838729be6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7dac163-6724-40e9-965c-f30442989783",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "640ead9c-fcf1-4121-8e9e-11a70bb6c1a4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97479966-6e56-47bf-93d5-e9df75f2906f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8aad2dc-754c-4129-82da-ba692ed92654",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ff01a09-94c5-4ae9-be82-77058b1e5be3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fa4911f-1952-4d31-bc53-54819a512525",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b2fc80a-24e8-4e22-a3be-c2438dade551",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47cd5a2b-857e-4752-b8eb-b3d586ce0615",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd770fac-ce5a-49cd-85aa-c13a21bfb863",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6f0ead7-228a-4cbd-a358-2ca55de353e4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42ab146e-0e3b-432a-9387-6c1c7e4662f0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "aa2e7540-dc56-41f9-8a06-2accb8a3cf94",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import RNA\n",
    "sol_1 = 'CUGCUUGGUUUGGGCCCUUUCUUUCCCCGCCCUAUACGGGGGUAAUCGUGGUCAAGGGGGUCGGUGGAUUGACCGAACUUUGAUUCACGGUUAUUUCGAUGUGGGGCAAUAAGUAG'\n",
    "sol_2 = 'CGUUCGGCCAUGUCCUCGAAAAAUUGACGCUAAACGGCAUACCGGCGAUUUUUAGGCUACUCACCGAAAAGGGUGGCGCUUGACAGAUUGUUGGUGUUACGUUUGGCACCCGAAUG'\n",
    "sol_3 = 'UUGACCCUGGGCGUGGUGUGGGUGAACGAGCAGUGUCUGAAUAUUUUAGUCCACCCUUGCUGGGGCCUCUAUUCUAUAGGGUGAGGUUGGAAUAUUUUAAUAUUGUUGUGGGUCGA'\n",
    "sol_4 = 'GGUGGAGAAUAUCGCCUAGCCCUAACGAGCGCGCAUAUAUAGGCUUUUGACGGUGUGCAGCAGAGUGGACCCUCUGAUACGCUAGUUGGAGGCUUGUUAGUGUGUGUAACUCCACC'\n",
    "\n",
    "objective_structure_simple_1 = '(((((((....(((...........)))((((((((..(((((((((((((((((((...(((((......))))).)))))).)))))))))))))..))))))))..)))))))'\n",
    "\n",
    "sec_struct, energy = RNA.fold(sol_3)\n",
    "sec_struct == objective_structure_simple_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "deb0267c-01f2-42ae-bae4-7a6a6083be52",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sec_struct == objective_structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6286786d-41f7-40a2-93ea-e70492595a28",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.learn(total_timesteps=25000)\n",
    "model.save(\"ppo_cartpole\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
