{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9d8fbc93-3148-41d1-ab8e-1ec42681ae7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4d78a310-2a2d-4ab2-b180-98ebb67998e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from environment import RNAInvEnvironment, make_vec_env, Monitor\n",
    "from RNA_helper import get_puzzle\n",
    "import torch as th\n",
    "from models import EmbeddinsFeatureExtractor\n",
    "from stable_baselines3.common import logger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "30e1b624-d75b-4bb1-8948-109f8b7c1544",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "389"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1, 41, 84, 92, 97\n",
    "puzzle_idx=84\n",
    "objective_structure, sequence, puzzle_name = get_puzzle(idx=puzzle_idx, return_name=True, verbose=False)\n",
    "len(objective_structure)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2a0a0611-cc1f-4998-ad92-194815047030",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "snowflake_necklace_(_or_v2.0_)_512_3\n"
     ]
    }
   ],
   "source": [
    "max_steps = 1\n",
    "features_dim = 512\n",
    "EMBEDDING_DIM = 3\n",
    "model_name = puzzle_name.lower().replace(' ', '_') + f'_{features_dim}_{EMBEDDING_DIM}'\n",
    "print(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3c3f5cff-d137-4d55-8bf9-5d18305c7096",
   "metadata": {},
   "outputs": [],
   "source": [
    "env_kwargs = {\n",
    "    'objective_structure': objective_structure,\n",
    "    'max_steps': max_steps,\n",
    "    'tuple_obs_space': True,\n",
    "    'metric_type': 'total_distance',\n",
    "    'sequences_file': f'solved_puzzles/{model_name}.txt'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9aeed67c-4ab9-4129-91b1-02bbb7d3e212",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/tljh/user/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "  warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    }
   ],
   "source": [
    "n_envs=12\n",
    "env = make_vec_env(RNAInvEnvironment, n_envs=n_envs, env_kwargs=env_kwargs)\n",
    "# env = RNAInvEnvironment(objective_structure=objective_structure, max_steps=max_steps, tuple_obs_space=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fc0f704e-0fe1-4841-b2af-d0173b63ea79",
   "metadata": {},
   "outputs": [],
   "source": [
    "from stable_baselines3 import PPO\n",
    "from stable_baselines3.common.callbacks import EvalCallback\n",
    "from stable_baselines3.common.policies import ActorCriticPolicy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f2e171ce-1569-4a2e-b2ca-48f87a033717",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((12, 389), torch.Size([12, 512]))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Teste embeddings\n",
    "\n",
    "obs = env.reset()\n",
    "efe = EmbeddinsFeatureExtractor(env.observation_space, EMBEDDING_DIM=EMBEDDING_DIM, features_dim=features_dim).cuda()\n",
    "out = efe(th.as_tensor(obs).cuda())\n",
    "obs.shape, out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "128d3baf-84c9-41b6-80a0-f8398574d3fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# th.as_tensor(env.observation_space.sample())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3b582fb0-4051-4534-958a-3154b4113610",
   "metadata": {},
   "outputs": [],
   "source": [
    "policy_kwargs = dict(\n",
    "    features_extractor_class=EmbeddinsFeatureExtractor,\n",
    "    features_extractor_kwargs=dict(EMBEDDING_DIM=EMBEDDING_DIM, features_dim=features_dim),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5da7e0b4-c8d5-42cb-b4e7-ca80404eaff8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n"
     ]
    }
   ],
   "source": [
    "model = PPO(\n",
    "    ActorCriticPolicy,\n",
    "    env,\n",
    "    verbose=1,\n",
    "    tensorboard_log='tensorboard_logs',\n",
    "    n_steps=512,\n",
    "    gamma=0.99,\n",
    "    policy_kwargs=policy_kwargs\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "051b89fb-f97f-4ac7-8d16-8c5a6222ebcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# log_path = f\"logs/{model_name}\"\n",
    "# # set up logger\n",
    "# new_logger = logger.configure(log_path, [\"stdout\", \"csv\", \"log\", \"tensorboard\", \"json\"])\n",
    "# model.set_logger(new_logger)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "94faa1ad-4164-4488-b59e-0eeecf7292c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# eval_env = make_vec_env(\n",
    "#     RNAInvEnvironment, n_envs=1,\n",
    "#     env_kwargs={'objective_structure': objective_structure, 'max_steps': max_steps, 'tuple_obs_space': True}\n",
    "# )\n",
    "\n",
    "eval_env = make_vec_env(\n",
    "    RNAInvEnvironment, n_envs=1,\n",
    "    env_kwargs=env_kwargs,\n",
    "    monitor_dir=f'logs/{model_name}',\n",
    "    monitor_kwargs={'info_keywords': ('free_energy', 'structure_distance', 'energy_to_objective', 'energy_reward', 'distance_reward')}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fd71229b-f87c-4228-9d9c-cdfdf39c5045",
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_callback = EvalCallback(\n",
    "    eval_env = eval_env,\n",
    "    eval_freq=512*5,\n",
    "    n_eval_episodes=1024,\n",
    "    deterministic=True,\n",
    "    verbose=1,\n",
    "    best_model_save_path=f'models/{model_name}',\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "718fc440-11fd-44b4-a991-aaadb84d1af4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logging to tensorboard_logs/snowflake_necklace_(_or_v2.0_)_512_3_1\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1        |\n",
      "|    ep_rew_mean     | 0.29     |\n",
      "| time/              |          |\n",
      "|    fps             | 5        |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 1127     |\n",
      "|    total_timesteps | 6144     |\n",
      "---------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1         |\n",
      "|    ep_rew_mean          | 0.294     |\n",
      "| time/                   |           |\n",
      "|    fps                  | 5         |\n",
      "|    iterations           | 2         |\n",
      "|    time_elapsed         | 2394      |\n",
      "|    total_timesteps      | 12288     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 3.6588523 |\n",
      "|    clip_fraction        | 0.807     |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -439      |\n",
      "|    explained_variance   | -151      |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | -0.127    |\n",
      "|    n_updates            | 10        |\n",
      "|    policy_gradient_loss | -0.105    |\n",
      "|    value_loss           | 0.00468   |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| rollout/                |          |\n",
      "|    ep_len_mean          | 1        |\n",
      "|    ep_rew_mean          | 0.293    |\n",
      "| time/                   |          |\n",
      "|    fps                  | 5        |\n",
      "|    iterations           | 3        |\n",
      "|    time_elapsed         | 3661     |\n",
      "|    total_timesteps      | 18432    |\n",
      "| train/                  |          |\n",
      "|    approx_kl            | 17.63697 |\n",
      "|    clip_fraction        | 0.892    |\n",
      "|    clip_range           | 0.2      |\n",
      "|    entropy_loss         | -439     |\n",
      "|    explained_variance   | -0.0658  |\n",
      "|    learning_rate        | 0.0003   |\n",
      "|    loss                 | -0.148   |\n",
      "|    n_updates            | 20       |\n",
      "|    policy_gradient_loss | -0.104   |\n",
      "|    value_loss           | 0.00129  |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1         |\n",
      "|    ep_rew_mean          | 0.293     |\n",
      "| time/                   |           |\n",
      "|    fps                  | 4         |\n",
      "|    iterations           | 4         |\n",
      "|    time_elapsed         | 4925      |\n",
      "|    total_timesteps      | 24576     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 40.113045 |\n",
      "|    clip_fraction        | 0.901     |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -438      |\n",
      "|    explained_variance   | -0.0302   |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | -0.136    |\n",
      "|    n_updates            | 30        |\n",
      "|    policy_gradient_loss | -0.109    |\n",
      "|    value_loss           | 0.00124   |\n",
      "---------------------------------------\n",
      "Eval num_timesteps=30720, episode_reward=0.47 +/- 0.05\n",
      "Episode length: 1.00 +/- 0.00\n",
      "---------------------------------------\n",
      "| eval/                   |           |\n",
      "|    mean_ep_length       | 1         |\n",
      "|    mean_reward          | 0.469     |\n",
      "| time/                   |           |\n",
      "|    total timesteps      | 30720     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 75.481834 |\n",
      "|    clip_fraction        | 0.907     |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -437      |\n",
      "|    explained_variance   | -0.0179   |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | -0.131    |\n",
      "|    n_updates            | 40        |\n",
      "|    policy_gradient_loss | -0.101    |\n",
      "|    value_loss           | 0.00124   |\n",
      "---------------------------------------\n",
      "New best mean reward!\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1        |\n",
      "|    ep_rew_mean     | 0.3      |\n",
      "| time/              |          |\n",
      "|    fps             | 4        |\n",
      "|    iterations      | 5        |\n",
      "|    time_elapsed    | 6398     |\n",
      "|    total_timesteps | 30720    |\n",
      "---------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1         |\n",
      "|    ep_rew_mean          | 0.306     |\n",
      "| time/                   |           |\n",
      "|    fps                  | 4         |\n",
      "|    iterations           | 6         |\n",
      "|    time_elapsed         | 7653      |\n",
      "|    total_timesteps      | 36864     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 96.054405 |\n",
      "|    clip_fraction        | 0.912     |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -437      |\n",
      "|    explained_variance   | -0.0275   |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | -0.157    |\n",
      "|    n_updates            | 50        |\n",
      "|    policy_gradient_loss | -0.111    |\n",
      "|    value_loss           | 0.00132   |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| rollout/                |          |\n",
      "|    ep_len_mean          | 1        |\n",
      "|    ep_rew_mean          | 0.315    |\n",
      "| time/                   |          |\n",
      "|    fps                  | 4        |\n",
      "|    iterations           | 7        |\n",
      "|    time_elapsed         | 8907     |\n",
      "|    total_timesteps      | 43008    |\n",
      "| train/                  |          |\n",
      "|    approx_kl            | 138.297  |\n",
      "|    clip_fraction        | 0.918    |\n",
      "|    clip_range           | 0.2      |\n",
      "|    entropy_loss         | -435     |\n",
      "|    explained_variance   | -0.023   |\n",
      "|    learning_rate        | 0.0003   |\n",
      "|    loss                 | -0.133   |\n",
      "|    n_updates            | 60       |\n",
      "|    policy_gradient_loss | -0.103   |\n",
      "|    value_loss           | 0.00133  |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| rollout/                |          |\n",
      "|    ep_len_mean          | 1        |\n",
      "|    ep_rew_mean          | 0.319    |\n",
      "| time/                   |          |\n",
      "|    fps                  | 4        |\n",
      "|    iterations           | 8        |\n",
      "|    time_elapsed         | 10175    |\n",
      "|    total_timesteps      | 49152    |\n",
      "| train/                  |          |\n",
      "|    approx_kl            | 187.4688 |\n",
      "|    clip_fraction        | 0.92     |\n",
      "|    clip_range           | 0.2      |\n",
      "|    entropy_loss         | -434     |\n",
      "|    explained_variance   | -0.00929 |\n",
      "|    learning_rate        | 0.0003   |\n",
      "|    loss                 | -0.153   |\n",
      "|    n_updates            | 70       |\n",
      "|    policy_gradient_loss | -0.107   |\n",
      "|    value_loss           | 0.00132  |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1         |\n",
      "|    ep_rew_mean          | 0.34      |\n",
      "| time/                   |           |\n",
      "|    fps                  | 4         |\n",
      "|    iterations           | 9         |\n",
      "|    time_elapsed         | 11426     |\n",
      "|    total_timesteps      | 55296     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 211.03569 |\n",
      "|    clip_fraction        | 0.921     |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -433      |\n",
      "|    explained_variance   | -0.0116   |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | -0.137    |\n",
      "|    n_updates            | 80        |\n",
      "|    policy_gradient_loss | -0.109    |\n",
      "|    value_loss           | 0.00135   |\n",
      "---------------------------------------\n",
      "Eval num_timesteps=61440, episode_reward=0.63 +/- 0.05\n",
      "Episode length: 1.00 +/- 0.00\n",
      "---------------------------------------\n",
      "| eval/                   |           |\n",
      "|    mean_ep_length       | 1         |\n",
      "|    mean_reward          | 0.629     |\n",
      "| time/                   |           |\n",
      "|    total timesteps      | 61440     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 239.59424 |\n",
      "|    clip_fraction        | 0.922     |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -431      |\n",
      "|    explained_variance   | -0.00923  |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | -0.156    |\n",
      "|    n_updates            | 90        |\n",
      "|    policy_gradient_loss | -0.0952   |\n",
      "|    value_loss           | 0.00145   |\n",
      "---------------------------------------\n",
      "New best mean reward!\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1        |\n",
      "|    ep_rew_mean     | 0.331    |\n",
      "| time/              |          |\n",
      "|    fps             | 4        |\n",
      "|    iterations      | 10       |\n",
      "|    time_elapsed    | 12856    |\n",
      "|    total_timesteps | 61440    |\n",
      "---------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1         |\n",
      "|    ep_rew_mean          | 0.333     |\n",
      "| time/                   |           |\n",
      "|    fps                  | 4         |\n",
      "|    iterations           | 11        |\n",
      "|    time_elapsed         | 14086     |\n",
      "|    total_timesteps      | 67584     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 306.72504 |\n",
      "|    clip_fraction        | 0.923     |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -429      |\n",
      "|    explained_variance   | -0.0122   |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | -0.132    |\n",
      "|    n_updates            | 100       |\n",
      "|    policy_gradient_loss | -0.0955   |\n",
      "|    value_loss           | 0.00141   |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1         |\n",
      "|    ep_rew_mean          | 0.358     |\n",
      "| time/                   |           |\n",
      "|    fps                  | 4         |\n",
      "|    iterations           | 12        |\n",
      "|    time_elapsed         | 15308     |\n",
      "|    total_timesteps      | 73728     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 278.55716 |\n",
      "|    clip_fraction        | 0.925     |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -426      |\n",
      "|    explained_variance   | -0.00666  |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | -0.145    |\n",
      "|    n_updates            | 110       |\n",
      "|    policy_gradient_loss | 0.0267    |\n",
      "|    value_loss           | 0.00149   |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| rollout/                |          |\n",
      "|    ep_len_mean          | 1        |\n",
      "|    ep_rew_mean          | 0.36     |\n",
      "| time/                   |          |\n",
      "|    fps                  | 4        |\n",
      "|    iterations           | 13       |\n",
      "|    time_elapsed         | 16520    |\n",
      "|    total_timesteps      | 79872    |\n",
      "| train/                  |          |\n",
      "|    approx_kl            | 286.4913 |\n",
      "|    clip_fraction        | 0.929    |\n",
      "|    clip_range           | 0.2      |\n",
      "|    entropy_loss         | -423     |\n",
      "|    explained_variance   | -0.0161  |\n",
      "|    learning_rate        | 0.0003   |\n",
      "|    loss                 | -0.144   |\n",
      "|    n_updates            | 120      |\n",
      "|    policy_gradient_loss | -0.106   |\n",
      "|    value_loss           | 0.00161  |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1         |\n",
      "|    ep_rew_mean          | 0.377     |\n",
      "| time/                   |           |\n",
      "|    fps                  | 4         |\n",
      "|    iterations           | 14        |\n",
      "|    time_elapsed         | 17720     |\n",
      "|    total_timesteps      | 86016     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 312.16153 |\n",
      "|    clip_fraction        | 0.931     |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -419      |\n",
      "|    explained_variance   | -0.0167   |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | -0.15     |\n",
      "|    n_updates            | 130       |\n",
      "|    policy_gradient_loss | -0.0719   |\n",
      "|    value_loss           | 0.00183   |\n",
      "---------------------------------------\n",
      "Eval num_timesteps=92160, episode_reward=0.68 +/- 0.04\n",
      "Episode length: 1.00 +/- 0.00\n",
      "---------------------------------------\n",
      "| eval/                   |           |\n",
      "|    mean_ep_length       | 1         |\n",
      "|    mean_reward          | 0.681     |\n",
      "| time/                   |           |\n",
      "|    total timesteps      | 92160     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 270.35574 |\n",
      "|    clip_fraction        | 0.933     |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -414      |\n",
      "|    explained_variance   | -0.0122   |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | -0.15     |\n",
      "|    n_updates            | 140       |\n",
      "|    policy_gradient_loss | -0.0947   |\n",
      "|    value_loss           | 0.00178   |\n",
      "---------------------------------------\n",
      "New best mean reward!\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1        |\n",
      "|    ep_rew_mean     | 0.388    |\n",
      "| time/              |          |\n",
      "|    fps             | 4        |\n",
      "|    iterations      | 15       |\n",
      "|    time_elapsed    | 19061    |\n",
      "|    total_timesteps | 92160    |\n",
      "---------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1         |\n",
      "|    ep_rew_mean          | 0.405     |\n",
      "| time/                   |           |\n",
      "|    fps                  | 4         |\n",
      "|    iterations           | 16        |\n",
      "|    time_elapsed         | 20192     |\n",
      "|    total_timesteps      | 98304     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 248.84076 |\n",
      "|    clip_fraction        | 0.931     |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -410      |\n",
      "|    explained_variance   | -0.0144   |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | -0.162    |\n",
      "|    n_updates            | 150       |\n",
      "|    policy_gradient_loss | -0.0909   |\n",
      "|    value_loss           | 0.00185   |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1         |\n",
      "|    ep_rew_mean          | 0.419     |\n",
      "| time/                   |           |\n",
      "|    fps                  | 4         |\n",
      "|    iterations           | 17        |\n",
      "|    time_elapsed         | 21314     |\n",
      "|    total_timesteps      | 104448    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 322.86145 |\n",
      "|    clip_fraction        | 0.934     |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -405      |\n",
      "|    explained_variance   | -0.00605  |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | -0.148    |\n",
      "|    n_updates            | 160       |\n",
      "|    policy_gradient_loss | -0.0984   |\n",
      "|    value_loss           | 0.00193   |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1         |\n",
      "|    ep_rew_mean          | 0.434     |\n",
      "| time/                   |           |\n",
      "|    fps                  | 4         |\n",
      "|    iterations           | 18        |\n",
      "|    time_elapsed         | 22465     |\n",
      "|    total_timesteps      | 110592    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 246.00085 |\n",
      "|    clip_fraction        | 0.935     |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -400      |\n",
      "|    explained_variance   | -0.014    |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | -0.14     |\n",
      "|    n_updates            | 170       |\n",
      "|    policy_gradient_loss | -0.0624   |\n",
      "|    value_loss           | 0.00197   |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1         |\n",
      "|    ep_rew_mean          | 0.453     |\n",
      "| time/                   |           |\n",
      "|    fps                  | 4         |\n",
      "|    iterations           | 19        |\n",
      "|    time_elapsed         | 23615     |\n",
      "|    total_timesteps      | 116736    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 231.98543 |\n",
      "|    clip_fraction        | 0.935     |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -394      |\n",
      "|    explained_variance   | -0.0218   |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | -0.138    |\n",
      "|    n_updates            | 180       |\n",
      "|    policy_gradient_loss | -0.0939   |\n",
      "|    value_loss           | 0.00203   |\n",
      "---------------------------------------\n",
      "Eval num_timesteps=122880, episode_reward=0.70 +/- 0.04\n",
      "Episode length: 1.00 +/- 0.00\n",
      "---------------------------------------\n",
      "| eval/                   |           |\n",
      "|    mean_ep_length       | 1         |\n",
      "|    mean_reward          | 0.702     |\n",
      "| time/                   |           |\n",
      "|    total timesteps      | 122880    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 220.83418 |\n",
      "|    clip_fraction        | 0.935     |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -388      |\n",
      "|    explained_variance   | -0.0106   |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | -0.13     |\n",
      "|    n_updates            | 190       |\n",
      "|    policy_gradient_loss | -0.0849   |\n",
      "|    value_loss           | 0.00213   |\n",
      "---------------------------------------\n",
      "New best mean reward!\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1        |\n",
      "|    ep_rew_mean     | 0.465    |\n",
      "| time/              |          |\n",
      "|    fps             | 4        |\n",
      "|    iterations      | 20       |\n",
      "|    time_elapsed    | 24935    |\n",
      "|    total_timesteps | 122880   |\n",
      "---------------------------------\n",
      "--------------------------------------\n",
      "| rollout/                |          |\n",
      "|    ep_len_mean          | 1        |\n",
      "|    ep_rew_mean          | 0.474    |\n",
      "| time/                   |          |\n",
      "|    fps                  | 4        |\n",
      "|    iterations           | 21       |\n",
      "|    time_elapsed         | 26069    |\n",
      "|    total_timesteps      | 129024   |\n",
      "| train/                  |          |\n",
      "|    approx_kl            | 192.2281 |\n",
      "|    clip_fraction        | 0.935    |\n",
      "|    clip_range           | 0.2      |\n",
      "|    entropy_loss         | -382     |\n",
      "|    explained_variance   | -0.0166  |\n",
      "|    learning_rate        | 0.0003   |\n",
      "|    loss                 | -0.143   |\n",
      "|    n_updates            | 200      |\n",
      "|    policy_gradient_loss | -0.097   |\n",
      "|    value_loss           | 0.00215  |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1         |\n",
      "|    ep_rew_mean          | 0.486     |\n",
      "| time/                   |           |\n",
      "|    fps                  | 4         |\n",
      "|    iterations           | 22        |\n",
      "|    time_elapsed         | 27197     |\n",
      "|    total_timesteps      | 135168    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 134.09216 |\n",
      "|    clip_fraction        | 0.936     |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -375      |\n",
      "|    explained_variance   | -0.00546  |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | -0.136    |\n",
      "|    n_updates            | 210       |\n",
      "|    policy_gradient_loss | -0.0963   |\n",
      "|    value_loss           | 0.00226   |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1         |\n",
      "|    ep_rew_mean          | 0.509     |\n",
      "| time/                   |           |\n",
      "|    fps                  | 4         |\n",
      "|    iterations           | 23        |\n",
      "|    time_elapsed         | 28313     |\n",
      "|    total_timesteps      | 141312    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 190.54796 |\n",
      "|    clip_fraction        | 0.935     |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -370      |\n",
      "|    explained_variance   | -0.0172   |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | -0.143    |\n",
      "|    n_updates            | 220       |\n",
      "|    policy_gradient_loss | -0.0942   |\n",
      "|    value_loss           | 0.00227   |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1         |\n",
      "|    ep_rew_mean          | 0.521     |\n",
      "| time/                   |           |\n",
      "|    fps                  | 5         |\n",
      "|    iterations           | 24        |\n",
      "|    time_elapsed         | 29424     |\n",
      "|    total_timesteps      | 147456    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 181.35974 |\n",
      "|    clip_fraction        | 0.935     |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -362      |\n",
      "|    explained_variance   | -0.0156   |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | -0.146    |\n",
      "|    n_updates            | 230       |\n",
      "|    policy_gradient_loss | -0.0947   |\n",
      "|    value_loss           | 0.00238   |\n",
      "---------------------------------------\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "model.learn(\n",
    "    total_timesteps=1_000_000,\n",
    "    tb_log_name=model_name,\n",
    "    callback=[eval_callback]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0bf2b51-fca7-4749-b51b-3142e7bd510d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2de6c137-2676-4ad7-8d9c-74cb97e73e2c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "124928ba-c5ef-4ab9-8ad7-c0faa8afb217",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a27ed65d-e585-47f8-99e4-34c7684d18e9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80d61acd-d2ab-4dbf-beec-e1ee9df9c0e2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7cc1d02-3d4e-4b06-bc3d-abe5def7ff3f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c8ac3a3-b811-44f2-9ee4-c5f87357a9d1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce2bb9d4-0b7f-4c0b-ab52-c6ad99a0ebc9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afbbfacf-cc1d-49db-a230-ffc7db8159bc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15817702-398d-405a-a23d-210454d69782",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1db7281-98c4-4989-bad3-5c1e1431ca2d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "566fc605-e522-45c0-8ddb-896e8b82c0e3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "78bb47a0-b750-43d7-8bab-8d2e3acd322f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from evaluation import evaluate_policy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cd0f6ba-b0ed-46fb-916e-ec3840a41780",
   "metadata": {},
   "outputs": [],
   "source": [
    "Monitor("
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "a4d16dc6-9bca-492e-8428-2f6524fbc65a",
   "metadata": {},
   "outputs": [],
   "source": [
    "info_keywords = ('free_energy',)\n",
    "reset_keywords = ('free_energy',)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "188d3eb0-28ae-4dde-b80a-1a39852f947f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('free_energy', 'free_energy')"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "info_keywords + reset_keywords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4798acfd-8140-4e0f-9a32-c8d976f2670f",
   "metadata": {},
   "outputs": [],
   "source": [
    "'free_energy': energy,\n",
    "            'folding_struc': current_structure,\n",
    "            'structure_distance': new_objective_distance,\n",
    "            'energy_to_objective': new_energy,\n",
    "            'energy_reward': energy_reward,\n",
    "            'distance_reward': distance_reward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "5cf170a8-22cc-42f3-8b85-2af99e8121b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Monitor(filename='logs/test')\n",
    "\n",
    "\n",
    "eval_env = make_vec_env(\n",
    "    RNAInvEnvironment, n_envs=1,\n",
    "    env_kwargs=env_kwargs,\n",
    "    monitor_dir='logs',\n",
    "    monitor_kwargs={'info_keywords': ('free_energy', 'folding_struc', 'structure_distance', 'energy_to_objective', 'energy_reward', 'distance_reward')}\n",
    ")\n",
    "# eval_env = RNAInvEnvironment(**env_kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "0f713046-7f21-4300-968b-83cd3eeea8ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_reward, std_reward, mean_length = evaluate_policy(model, eval_env, n_eval_episodes=1, deterministic=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "eba56777-8820-4fd2-9361-4c0838729be6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(211.800003, 0.0, 1.0)"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_reward, std_reward, mean_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "e7dac163-6724-40e9-965c-f30442989783",
   "metadata": {},
   "outputs": [],
   "source": [
    "d = {'free_energy': -280.5, 'folding_struc': '(((((((((((((((.((.((.((((((((((.(((...))).)))))))).((.((..((.((((..(.(((.((((.(((..(((.(((((.((.((((((.((.((((..((.((.....)).)).)))).)).)))))).)).))))).)))..))).)))).))).)..)).)).))..)).)).((((.(.((........)).).)))).(((((((((.((....)).)))))))))....(((((.(((((((((.(((....((.(((....(.((..(..((.(((((.(((.....))).))))).))..)..)).)......))).))....))).))))))))).))))).)).)).)).)))))))))))))))', 'structure_distance': 0.37630662020905925, 'energy_to_objective': -172.6999969482422, 'energy_reward': 200.89999771118164, 'distance_reward': 0.04878048780487809, 'episode': {'r': 200.899998, 'l': 1, 't': 795.51385}, 'terminal_observation': [0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 3, 3, 3, 3, 3, 0, 0, 0, 0, 3, 3, 0, 0, 3, 0, 3, 3, 1, 0, 0, 3, 0, 0, 3, 0, 1, 1, 3, 0, 0, 3, 0, 0, 3, 0, 3, 1, 2, 0, 0, 3, 0, 0, 3, 0, 0, 2, 2, 0, 0, 3, 0, 0, 3, 0, 1, 0, 2, 0, 0, 3, 0, 0, 0, 3, 3, 3, 0, 0, 3, 3, 0, 2, 0, 1, 0, 0, 0, 3, 0, 0, 0, 0, 0, 3, 0, 0, 3, 0, 0, 1, 1, 0, 0, 3, 0, 0, 3, 0, 1, 0, 2, 0, 0, 3, 0, 0, 3, 0, 1, 0, 0, 0, 0, 3, 0, 0, 3, 0, 3, 0, 3, 0, 0, 3, 0, 0, 3, 0, 2, 1, 3, 0, 0, 3, 0, 0, 3, 3, 3, 3, 0, 0, 3, 3, 0, 2, 0, 3, 0, 0, 0, 3, 0, 0, 0, 0, 3, 3, 0, 0, 3, 0, 2, 2, 1, 2, 0, 3, 0, 0, 3, 0, 2, 1, 1, 0, 0, 3, 0, 0, 3, 0, 1, 0, 3, 2, 0, 3, 0, 0, 3, 0, 0, 2, 0, 2, 0, 3, 0, 0, 0, 0, 3, 0, 1, 2, 3, 3, 0, 0, 0, 3, 3, 3, 0, 0, 3, 3, 0, 1, 1, 3, 0, 0, 0, 3, 0, 0, 0, 3, 3, 3, 0, 0, 3, 0, 0, 0, 0, 0, 0, 3, 0, 0, 3, 0, 3, 1, 0, 0, 0, 3, 0, 0, 3, 0, 1, 2, 3, 0, 0, 3, 0, 0, 3, 0, 0, 2, 3, 0, 0, 3, 0, 0, 3, 0, 2, 0, 2, 0, 0, 3, 0, 0, 0, 0, 3, 3, 0, 0, 3, 3, 0, 1, 3, 0, 0, 0, 0, 3, 0, 0, 0, 3, 3, 3, 0, 0, 3, 0, 2, 3, 0, 0, 0, 3, 0, 0, 0, 0, 0, 2, 1, 2, 3, 3, 0, 0, 3, 0, 2, 2, 2, 0, 0, 3, 0, 0, 3, 0, 3, 1, 3, 2, 0, 3, 0, 0, 3, 0, 3, 1, 1, 0, 0, 3, 0, 0, 0, 0, 3, 3, 0, 0, 0, 0, 0, 0, 0, 3, 3, 3, 3, 3, 3, 3, 3, 3]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "c60a7d48-729b-4dae-8c52-9b9459ab0e1a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['free_energy', 'folding_struc', 'structure_distance', 'energy_to_objective', 'energy_reward', 'distance_reward', 'episode', 'terminal_observation'])"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "640ead9c-fcf1-4121-8e9e-11a70bb6c1a4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97479966-6e56-47bf-93d5-e9df75f2906f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8aad2dc-754c-4129-82da-ba692ed92654",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ff01a09-94c5-4ae9-be82-77058b1e5be3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fa4911f-1952-4d31-bc53-54819a512525",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b2fc80a-24e8-4e22-a3be-c2438dade551",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47cd5a2b-857e-4752-b8eb-b3d586ce0615",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd770fac-ce5a-49cd-85aa-c13a21bfb863",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6f0ead7-228a-4cbd-a358-2ca55de353e4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42ab146e-0e3b-432a-9387-6c1c7e4662f0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "aa2e7540-dc56-41f9-8a06-2accb8a3cf94",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import RNA\n",
    "sol_1 = 'CUGCUUGGUUUGGGCCCUUUCUUUCCCCGCCCUAUACGGGGGUAAUCGUGGUCAAGGGGGUCGGUGGAUUGACCGAACUUUGAUUCACGGUUAUUUCGAUGUGGGGCAAUAAGUAG'\n",
    "sol_2 = 'CGUUCGGCCAUGUCCUCGAAAAAUUGACGCUAAACGGCAUACCGGCGAUUUUUAGGCUACUCACCGAAAAGGGUGGCGCUUGACAGAUUGUUGGUGUUACGUUUGGCACCCGAAUG'\n",
    "sol_3 = 'UUGACCCUGGGCGUGGUGUGGGUGAACGAGCAGUGUCUGAAUAUUUUAGUCCACCCUUGCUGGGGCCUCUAUUCUAUAGGGUGAGGUUGGAAUAUUUUAAUAUUGUUGUGGGUCGA'\n",
    "sol_4 = 'GGUGGAGAAUAUCGCCUAGCCCUAACGAGCGCGCAUAUAUAGGCUUUUGACGGUGUGCAGCAGAGUGGACCCUCUGAUACGCUAGUUGGAGGCUUGUUAGUGUGUGUAACUCCACC'\n",
    "\n",
    "objective_structure_simple_1 = '(((((((....(((...........)))((((((((..(((((((((((((((((((...(((((......))))).)))))).)))))))))))))..))))))))..)))))))'\n",
    "\n",
    "sec_struct, energy = RNA.fold(sol_3)\n",
    "sec_struct == objective_structure_simple_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "deb0267c-01f2-42ae-bae4-7a6a6083be52",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sec_struct == objective_structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6286786d-41f7-40a2-93ea-e70492595a28",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.learn(total_timesteps=25000)\n",
    "model.save(\"ppo_cartpole\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
